\section{Introduction} \label{sec:introduction}

Successful evolutionary search depends on the production of meaningful phenotypic variation that can be inherited by offspring.
Without useful heritable variation evolution stagnates.
The capacity of a population to generate useful heritable phenotypic variation is a key component of evolvability \cite{tarapore2015evolvability}.
Different evolving systems can exhibit different degrees of evolvability.
Natural systems, in particular, are argued to exhibit greater evolvability than computational systems \cite{wagner1996perspective}.
Understanding --- and replicating --- the evolvability of natural evolution is an open problem in computational evolution research \cite{mengistu2016evolvability}.

Evolvability is desirable in artificial evolution systems for practical ends --- more evolvable systems will help evolutionary algorithms to tackle sophisticated problems more effectively and efficiently \cite{bentley1999three, reisinger2007acquiring}.
Understanding evolvability is of great scientific interest for both evolutionary biologists and evolutionary computing researchers \cite{mengistu2016evolvability, pigliucci2008evolvability}, not only for optimization but also with respect to questions related to the evolution of complexity and open-ended evolution \cite{kirschner1998evolvability, hu2010evolvability}.

Indeed, there has been great interest in studying evolvability using computational systems and, in particular, developing techniques to promote evolvability in digital evolution \cite{kashtan2005spontaneous, mengistu2016evolvability, reisinger2005towards, cheney2013unshackling, nguyen2015innovation, lehman2013evolvability}.
Inspired by recent theoretical advances applying learning theory to the topic of evolvability \cite{kouvaris2017evolution, watson2016can}, we propose a methodology based on autoencoder artificial neural networks that allows evolvable genotype-phenotype encodings to be learned by training on phenotypes harvested from local fitness peaks.
We call our approach AutoMap.
One variant of AutoMap employs a denoising autoencoder to learn a representation that buffers phenotypes near local fitness peaks against mutation until a mutational threshold is reached where the phenotype shifts to the vicinity of a different local fitness peak.
The second AutoMap variant employs a bottlenecked autoencoder to learn a representation where small steps in the genotype space yield significant phenotypic novelty while protecting phenotypic viability.
In principle, the AutoMap methodology generalizes across a wide variety of computational evolution domains.
